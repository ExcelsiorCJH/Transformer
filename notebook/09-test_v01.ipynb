{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import omegaconf\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import ETTDataModule\n",
    "from src.model import Transformer\n",
    "from src.module import Trainer\n",
    "from src.module.utils import fix_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./transformer_config.yaml\"\n",
    "config = omegaconf.OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = ETTDataModule(**config.dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(**config.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed(config.train.seed)\n",
    "\n",
    "trainer = Trainer(config=config, model=model, dm=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(config, device: str):\n",
    "    version = config.version\n",
    "    dataset_name = config.dm.dataset_name\n",
    "    task_name = config.model.task_name\n",
    "\n",
    "    ckpt_list = glob.glob(\n",
    "        os.path.join(\n",
    "            config.train.ckpt_dir,\n",
    "            f\"version-{version}-{task_name}-{dataset_name.lower()}/*.pt\",\n",
    "        )\n",
    "    )\n",
    "    ckpt_list = sorted(ckpt_list, key=lambda e: e.split(\"_\")[-1], reverse=True)\n",
    "\n",
    "    state_dict = torch.load(ckpt_list[-1])\n",
    "    model = Transformer(**config.model)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.version = version\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = load_trained_model(config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_len = config.dm.pred_len\n",
    "label_len = config.dm.label_len\n",
    "task_type = config.dm.task_type\n",
    "\n",
    "inputs = []\n",
    "predicts, targets = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dm.test_dataloader(), total=len(dm.test_dataloader())):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # decoder input\n",
    "        dec_inp = torch.zeros_like(batch[\"future_values\"][:, -pred_len:, :]).float()\n",
    "        dec_inp = torch.cat(\n",
    "            [batch[\"future_values\"][:, :label_len, :], dec_inp], dim=1\n",
    "        ).float()\n",
    "\n",
    "        output = model(\n",
    "            past_values=batch[\"past_values\"],\n",
    "            past_time_features=batch[\"past_time_features\"],\n",
    "            future_values=dec_inp.to(device),\n",
    "            future_time_features=batch[\"future_time_features\"],\n",
    "        )\n",
    "        output = output[\"last_hidden_states\"]\n",
    "\n",
    "        f_dim = -1 if task_type == \"MS\" else 0\n",
    "        predict = output[:, -pred_len:, f_dim:]\n",
    "        target = batch[\"future_values\"][:, -pred_len:, f_dim:]\n",
    "\n",
    "        predict = predict.cpu().numpy()\n",
    "        target = target.cpu().numpy()\n",
    "\n",
    "        past_values = batch[\"past_values\"]\n",
    "        past_values = past_values.cpu().numpy()\n",
    "\n",
    "        if dm.scaler is not None:\n",
    "            shape = predict.shape\n",
    "            predict = dm.scaler.inverse_transform(predict.squeeze(0)).reshape(shape)\n",
    "            target = dm.scaler.inverse_transform(target.squeeze(0)).reshape(shape)\n",
    "            past_values = dm.scaler.inverse_transform(past_values.squeeze(0)).reshape(\n",
    "                shape\n",
    "            )\n",
    "\n",
    "        predict = predict[:, :, f_dim:]\n",
    "        target = target[:, :, f_dim:]\n",
    "\n",
    "        inputs.append(past_values)\n",
    "        predicts.append(predict)\n",
    "        targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(range(len(inputs)), 1).item()\n",
    "gt = np.concatenate((inputs[idx][0, :, f_dim], targets[idx][0, :, f_dim]), axis=0)\n",
    "pr = np.concatenate((inputs[idx][0, :, f_dim], predicts[idx][0, :, f_dim]), axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(gt, label=\"GroundTruth\", linewidth=2)\n",
    "if pr is not None:\n",
    "    plt.plot(pr, label=\"Prediction\", linewidth=2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from torchmetrics.regression import MeanAbsoluteError, MeanSquaredError\n",
    "from src.module.utils import fix_seed, load_trained_model, plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(config, dm, model) -> None:\n",
    "    pred_len = config.dm.pred_len\n",
    "    label_len = config.dm.label_len\n",
    "    task_type = config.dm.task_type\n",
    "\n",
    "    # model load\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    state_dict = load_trained_model(config)\n",
    "    model = Transformer(**config.model)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # dataloader\n",
    "    test_dataloader = dm.test_dataloader()\n",
    "\n",
    "    # save results\n",
    "    save_dir = \"results\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    save_path = os.path.join(\n",
    "        save_dir,\n",
    "        f'version-{config.version}-{config.model.task_name}-{config.dm.dataset_name.lower()}',\n",
    "    )\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    inputs = []\n",
    "    predicts, targets = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(\n",
    "            tqdm(test_dataloader, total=len(test_dataloader), desc=\"test\")\n",
    "        ):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # decoder input\n",
    "            dec_inp = torch.zeros_like(batch[\"future_values\"][:, -pred_len:, :]).float()\n",
    "            dec_inp = torch.cat(\n",
    "                [batch[\"future_values\"][:, :label_len, :], dec_inp], dim=1\n",
    "            ).float()\n",
    "\n",
    "            output = model(\n",
    "                past_values=batch[\"past_values\"],\n",
    "                past_time_features=batch[\"past_time_features\"],\n",
    "                future_values=dec_inp.to(device),\n",
    "                future_time_features=batch[\"future_time_features\"],\n",
    "            )\n",
    "            output = output[\"last_hidden_states\"]\n",
    "\n",
    "            f_dim = -1 if task_type == \"MS\" else 0\n",
    "            predict = output[:, -pred_len:, f_dim:]\n",
    "            target = batch[\"future_values\"][:, -pred_len:, f_dim:]\n",
    "\n",
    "            predict = predict.cpu().numpy()\n",
    "            target = target.cpu().numpy()\n",
    "\n",
    "            past_values = batch[\"past_values\"]\n",
    "            past_values = past_values.cpu().numpy()\n",
    "\n",
    "            if dm.scaler is not None:\n",
    "                shape = predict.shape\n",
    "                predict = dm.scaler.inverse_transform(predict.squeeze(0)).reshape(shape)\n",
    "                target = dm.scaler.inverse_transform(target.squeeze(0)).reshape(shape)\n",
    "                past_values = dm.scaler.inverse_transform(\n",
    "                    past_values.squeeze(0)\n",
    "                ).reshape(shape)\n",
    "\n",
    "            predict = predict[:, :, f_dim:]\n",
    "            target = target[:, :, f_dim:]\n",
    "\n",
    "            inputs.append(past_values)\n",
    "            predicts.append(predict)\n",
    "            targets.append(target)\n",
    "\n",
    "            if idx % 50 == 0:\n",
    "                gt = np.concatenate(\n",
    "                    (past_values[0, :, f_dim], target[0, :, f_dim]), axis=0\n",
    "                )\n",
    "                pr = np.concatenate(\n",
    "                    (past_values[0, :, f_dim], predict[0, :, f_dim]), axis=0\n",
    "                )\n",
    "\n",
    "                fname = os.path.join(save_path, f\"{idx}.png\")\n",
    "                plot(gt, pr, fname)\n",
    "\n",
    "    # save results\n",
    "    predicts = np.array(predicts)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    predicts = predicts.squeeze(1)\n",
    "    targets = targets.squeeze(1)\n",
    "\n",
    "    mean_absolute_error = MeanAbsoluteError()\n",
    "    mean_squared_error = MeanSquaredError()\n",
    "    mae = mean_absolute_error(torch.tensor(predicts), torch.tensor(targets)).item()\n",
    "    mse = mean_squared_error(torch.tensor(predicts), torch.tensor(targets)).item()\n",
    "\n",
    "    logging.basicConfig(\n",
    "        filename=os.path.join(save_path, \"result_metrics.log\"),\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s > %(message)s\",\n",
    "    )\n",
    "\n",
    "    logging.info(f\"MAE: {mae}, MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(config, dm, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('fedtracker')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "095ffe90df4ca297051b97375d5904c113ac48c02dcabb78607607a5f0a97f85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
