{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer - Probabilistic Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import ETTDataModule\n",
    "from src.model import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. prev setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_params = {\n",
    "    \"data_path\": \"../data/ETT-small/ETTh1.csv\",\n",
    "    \"task\": \"M\",\n",
    "    \"freq\": \"h\",\n",
    "    \"target\": \"OT\",\n",
    "    \"seq_len\": 96,\n",
    "    \"label_len\": 48,\n",
    "    \"pred_len\": 96,\n",
    "    \"use_scaler\": True,\n",
    "    \"use_time_enc\": True,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "\n",
    "dm = ETTDataModule(**dm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer_params\n",
    "Config = namedtuple(\n",
    "    \"Config\",\n",
    "    [\n",
    "        \"task_name\",\n",
    "        \"pred_len\",\n",
    "        \"seq_len\",\n",
    "        \"num_class\",\n",
    "        \"enc_in\",\n",
    "        \"dec_in\",\n",
    "        \"c_out\",\n",
    "        \"d_model\",\n",
    "        \"embed_type\",\n",
    "        \"freq\",\n",
    "        \"dropout\",\n",
    "        \"n_heads\",\n",
    "        \"d_keys\",\n",
    "        \"d_values\",\n",
    "        \"d_ff\",\n",
    "        \"scale\",\n",
    "        \"attention_dropout\",\n",
    "        \"output_attention\",\n",
    "        \"activation\",\n",
    "        \"num_enc_layers\",\n",
    "        \"num_dec_layers\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "configs = Config(\n",
    "    task_name=\"long_term_forecast\",\n",
    "    pred_len=96,\n",
    "    seq_len=None,\n",
    "    num_class=None,\n",
    "    enc_in=7,\n",
    "    dec_in=7,\n",
    "    c_out=7,\n",
    "    d_model=512,\n",
    "    embed_type=\"time_features\",\n",
    "    freq=\"h\",\n",
    "    dropout=0.1,\n",
    "    n_heads=8,\n",
    "    d_keys=None,\n",
    "    d_values=None,\n",
    "    d_ff=2048,\n",
    "    scale=None,\n",
    "    attention_dropout=0.1,\n",
    "    output_attention=True,\n",
    "    activation=\"gelu\",\n",
    "    num_enc_layers=2,\n",
    "    num_dec_layers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(**configs._asdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = dm.train_dataloader()\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "# decoder input\n",
    "label_len = 48\n",
    "dec_inp = torch.zeros_like(batch[\"future_values\"][:, -configs.pred_len :, :]).float()\n",
    "dec_inp = torch.cat([batch[\"future_values\"][:, :label_len, :], dec_inp], dim=1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    future_values=dec_inp,\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7532,  0.5016, -0.6780,  ..., -0.9313, -0.7630,  0.2696],\n",
       "         [-0.7095,  1.0485, -0.3392,  ..., -0.5668, -1.0276,  0.3088],\n",
       "         [-0.6347,  0.9774, -0.4741,  ..., -0.8312, -1.0052,  0.6853],\n",
       "         ...,\n",
       "         [-0.7334,  0.1655,  0.2394,  ..., -0.2001, -0.0030,  0.6181],\n",
       "         [-0.5439,  0.6911,  0.4149,  ..., -0.2567,  0.3115,  0.1636],\n",
       "         [-0.6202,  1.2147,  0.3297,  ..., -0.2797, -0.2696,  0.2670]],\n",
       "\n",
       "        [[ 0.1508, -0.3699, -1.1867,  ...,  0.1533,  0.1827, -0.7236],\n",
       "         [-0.0193, -0.2874, -0.8082,  ..., -0.2953,  0.2752, -0.6535],\n",
       "         [-0.1565, -0.5074, -0.8264,  ..., -0.1849,  0.0810, -0.1247],\n",
       "         ...,\n",
       "         [-0.4047, -0.2092,  0.2076,  ..., -0.0950,  0.4518,  0.2984],\n",
       "         [-0.0614, -0.0345,  0.2961,  ..., -0.2699,  0.5922,  0.1125],\n",
       "         [ 0.0262, -0.5969, -0.6184,  ..., -0.6735,  0.8110, -0.0223]],\n",
       "\n",
       "        [[ 0.6263, -0.0202,  0.3586,  ..., -0.4256,  0.2879,  0.0959],\n",
       "         [ 0.6704,  0.1471,  0.8849,  ..., -0.0131,  0.2700,  0.1850],\n",
       "         [ 0.6054,  0.4273,  1.1245,  ...,  0.3022,  0.3679,  0.0670],\n",
       "         ...,\n",
       "         [-0.1898, -0.3036, -0.0467,  ..., -0.5029,  0.8517,  0.3311],\n",
       "         [-0.3617, -0.4721,  0.4521,  ..., -0.6517,  0.4727,  0.0571],\n",
       "         [-0.0851, -0.4960,  0.2368,  ..., -0.4281,  0.9453,  0.4060]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.5066,  0.2875, -0.4566,  ...,  0.6936,  0.4517, -0.6536],\n",
       "         [ 0.5206, -0.0479, -0.1048,  ...,  0.6837,  0.8698, -0.3314],\n",
       "         [ 0.2199, -0.3503,  0.1105,  ...,  0.7729,  1.1579, -0.0391],\n",
       "         ...,\n",
       "         [-0.5006, -0.5970, -0.1321,  ..., -0.3105,  0.8760,  0.3272],\n",
       "         [-0.3432, -0.4787, -0.0793,  ..., -0.1572,  0.4040,  0.4413],\n",
       "         [ 0.0358, -0.6403,  0.2043,  ...,  0.2848,  0.4303,  0.8411]],\n",
       "\n",
       "        [[ 0.5048, -0.3215, -0.1932,  ...,  0.6297,  0.5926, -0.1957],\n",
       "         [ 0.5404, -0.4257,  0.0917,  ...,  1.0734,  0.8090, -0.2408],\n",
       "         [ 0.3754, -0.2139,  0.4552,  ...,  1.0944,  0.8732, -0.2735],\n",
       "         ...,\n",
       "         [-0.3765, -0.4508, -0.2621,  ..., -0.2218,  0.6719,  0.1050],\n",
       "         [-0.7216, -0.3839, -0.1555,  ..., -0.1240,  0.8117,  0.1599],\n",
       "         [ 0.1892, -0.8642, -0.0168,  ...,  0.5683,  1.1451,  0.3367]],\n",
       "\n",
       "        [[-0.0485,  0.2463, -0.5169,  ...,  0.9073,  0.3627, -0.5921],\n",
       "         [ 0.5474, -0.5762, -0.0175,  ...,  0.6931,  0.7416, -0.4601],\n",
       "         [ 0.4000, -0.4613,  0.3049,  ...,  0.9649,  1.0573, -0.5880],\n",
       "         ...,\n",
       "         [-0.5363, -0.5367, -0.1575,  ...,  0.1257,  0.8965,  0.1641],\n",
       "         [-0.4987, -0.4884, -0.0153,  ..., -0.1090,  0.4365,  0.0560],\n",
       "         [-0.0931, -0.4446,  0.2986,  ..., -0.0147,  0.4712,  0.5846]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"last_hidden_states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 144, 7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"future_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
