{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.dataset import ETTDataset\n",
    "from src.dataset.preprocess import load_data, trn_val_tst_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETTDataModule:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        task: str = \"M\",\n",
    "        freq: str = \"h\",\n",
    "        target: str = \"OT\",\n",
    "        seq_len: int = 96,\n",
    "        label_len: int = 48,\n",
    "        pred_len: int = 96,\n",
    "        use_scaler: bool = True,\n",
    "        use_time_enc: bool = True,\n",
    "        batch_size: int = 32,\n",
    "    ):\n",
    "        self.data_path = data_path\n",
    "        self.task = task\n",
    "        self.freq = freq\n",
    "        self.target = target\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = pred_len\n",
    "        self.use_scaler = use_scaler\n",
    "        self.use_time_enc = use_time_enc\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.scaler = None\n",
    "        if self.use_scaler:\n",
    "            self.scaler = StandardScaler()\n",
    "\n",
    "        self.split_idx_dict = {\n",
    "            \"train\": [0, 12 * 30 * 24],\n",
    "            \"val\": [12 * 30 * 24 - seq_len, 12 * 30 * 24 + 4 * 30 * 24],\n",
    "            \"test\": [12 * 30 * 24 + 4 * 30 * 24 - seq_len, 12 * 30 * 24 + 8 * 30 * 24],\n",
    "        }\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        df = load_data(self.data_path, task=self.task, target=self.target)\n",
    "        data_dict = trn_val_tst_split(df, self.split_idx_dict, self.scaler)\n",
    "\n",
    "        self.trainset = ETTDataset(\n",
    "            data_dict[\"train\"],\n",
    "            self.seq_len,\n",
    "            self.label_len,\n",
    "            self.pred_len,\n",
    "            self.freq,\n",
    "            self.use_time_enc,\n",
    "        )\n",
    "\n",
    "        self.valset = ETTDataset(\n",
    "            data_dict[\"val\"],\n",
    "            self.seq_len,\n",
    "            self.label_len,\n",
    "            self.pred_len,\n",
    "            self.freq,\n",
    "            self.use_time_enc,\n",
    "        )\n",
    "\n",
    "        self.testset = ETTDataset(\n",
    "            data_dict[\"test\"],\n",
    "            self.seq_len,\n",
    "            self.label_len,\n",
    "            self.pred_len,\n",
    "            self.freq,\n",
    "            self.use_time_enc,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.trainset, batch_size=self.batch_size, shuffle=True, drop_last=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valset, batch_size=self.batch_size, shuffle=True, drop_last=True\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valset, batch_size=self.batch_size, shuffle=False, drop_last=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_params = {\n",
    "    \"data_path\": \"../data/ETT-small/ETTh1.csv\",\n",
    "    \"task\": \"M\",\n",
    "    \"freq\": \"h\",\n",
    "    \"target\": \"OT\",\n",
    "    \"seq_len\": 96,\n",
    "    \"label_len\": 48,\n",
    "    \"pred_len\": 96,\n",
    "    \"use_scaler\": True,\n",
    "    \"use_time_enc\": True,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "\n",
    "dm = ETTDataModule(**dm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = dm.train_dataloader()\n",
    "val_dataloader = dm.val_dataloader()\n",
    "test_dataloader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['past_values', 'past_time_features', 'future_values', 'future_time_features'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96, 7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch[\"past_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('fedtracker')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "095ffe90df4ca297051b97375d5904c113ac48c02dcabb78607607a5f0a97f85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
