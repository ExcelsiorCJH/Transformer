{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import ETTDataModule\n",
    "from src.model import DataEmbedding\n",
    "from src.model import Attention\n",
    "from src.model import Encoder, Decoder\n",
    "from src.model import EncoderLayer, DecoderLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. prev setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_params = {\n",
    "    \"data_path\": \"../data/ETT-small/ETTh1.csv\",\n",
    "    \"task\": \"M\",\n",
    "    \"freq\": \"h\",\n",
    "    \"target\": \"OT\",\n",
    "    \"seq_len\": 96,\n",
    "    \"label_len\": 48,\n",
    "    \"pred_len\": 96,\n",
    "    \"use_scaler\": True,\n",
    "    \"use_time_enc\": True,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "\n",
    "dm = ETTDataModule(**dm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_params = {\n",
    "    \"c_in\": 7,\n",
    "    \"d_model\": 512,\n",
    "    \"embed_type\": \"time_features\",\n",
    "    \"freq\": \"h\",\n",
    "    \"dropout\": 0.1,\n",
    "}\n",
    "\n",
    "enc_embedding = DataEmbedding(**emb_params)\n",
    "dec_embedding = DataEmbedding(**emb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_params = {\n",
    "    \"d_model\": 512,\n",
    "    \"n_heads\": 8,\n",
    "    \"d_keys\": None,\n",
    "    \"d_values\": None,\n",
    "    \"scale\": None,\n",
    "    \"attention_dropout\": 0.1,\n",
    "    \"output_attention\": True,\n",
    "}\n",
    "\n",
    "attn_layer = Attention(**attn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_layer_params = {\n",
    "    \"attention\": Attention(**attn_params),\n",
    "    \"d_model\": 512,\n",
    "    \"d_ff\": 2048,\n",
    "    \"dropout\": 0.1,\n",
    "    \"activation\": \"gelu\",\n",
    "}\n",
    "\n",
    "dec_layer_params = {\n",
    "    \"self_attention\": Attention(**attn_params),\n",
    "    \"cross_attention\": Attention(**attn_params),\n",
    "    \"d_model\": 512,\n",
    "    \"d_ff\": 2048,\n",
    "    \"dropout\": 0.1,\n",
    "    \"activation\": \"gelu\",\n",
    "}\n",
    "\n",
    "\n",
    "d_model = 512\n",
    "num_enc_layers: int = 2\n",
    "num_dec_layers: int = 1\n",
    "c_out = 7\n",
    "\n",
    "encoder = Encoder(\n",
    "    enc_layers=[EncoderLayer(**enc_layer_params) for _ in range(num_enc_layers)],\n",
    "    norm_layer=nn.LayerNorm(d_model),\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    dec_layers=[DecoderLayer(**dec_layer_params) for _ in range(num_dec_layers)],\n",
    "    norm_layer=nn.LayerNorm(d_model),\n",
    "    projection=nn.Linear(d_model, c_out),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer_params\n",
    "Config = namedtuple(\n",
    "    \"Config\",\n",
    "    [\n",
    "        \"task_name\",\n",
    "        \"pred_len\",\n",
    "        \"seq_len\",\n",
    "        \"num_class\",\n",
    "        \"enc_in\",\n",
    "        \"dec_in\",\n",
    "        \"c_out\",\n",
    "        \"d_model\",\n",
    "        \"embed_type\",\n",
    "        \"freq\",\n",
    "        \"dropout\",\n",
    "        \"n_heads\",\n",
    "        \"d_keys\",\n",
    "        \"d_values\",\n",
    "        \"d_ff\",\n",
    "        \"scale\",\n",
    "        \"attention_dropout\",\n",
    "        \"output_attention\",\n",
    "        \"activation\",\n",
    "        \"num_enc_layers\",\n",
    "        \"num_dec_layers\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "configs = Config(\n",
    "    task_name=\"long_term_forecast\",\n",
    "    pred_len=96,\n",
    "    seq_len=None,\n",
    "    num_class=None,\n",
    "    enc_in=7,\n",
    "    dec_in=7,\n",
    "    c_out=7,\n",
    "    d_model=512,\n",
    "    embed_type=\"time_features\",\n",
    "    freq=\"h\",\n",
    "    dropout=0.1,\n",
    "    n_heads=8,\n",
    "    d_keys=None,\n",
    "    d_values=None,\n",
    "    d_ff=2048,\n",
    "    scale=None,\n",
    "    attention_dropout=0.1,\n",
    "    output_attention=True,\n",
    "    activation=\"gelu\",\n",
    "    num_enc_layers=2,\n",
    "    num_dec_layers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        task_name: str = \"long_term_forecast\",\n",
    "        pred_len: int = 96,\n",
    "        seq_len: int = None,\n",
    "        num_class: int = None,\n",
    "        enc_in: int = 7,\n",
    "        dec_in: int = 7,\n",
    "        c_out: int = 7,\n",
    "        d_model: int = 512,\n",
    "        embed_type: str = \"time_features\",\n",
    "        freq: str = \"h\",\n",
    "        dropout: float = 0.1,\n",
    "        n_heads: int = 8,\n",
    "        d_keys: int = None,\n",
    "        d_values: int = None,\n",
    "        d_ff: int = 2048,\n",
    "        scale: float = None,\n",
    "        attention_dropout: float = 0.1,\n",
    "        output_attention: bool = True,\n",
    "        activation: str = \"gelu\",\n",
    "        num_enc_layers: int = 2,\n",
    "        num_dec_layers: int = 1,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.task_name = task_name\n",
    "        self.pred_len = pred_len\n",
    "        self.output_attention = output_attention\n",
    "\n",
    "        # 1. Encoder embedding layer\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed_type, freq, dropout)\n",
    "\n",
    "        # 2. Encoder\n",
    "        enc_layer = EncoderLayer(\n",
    "            attention=Attention(\n",
    "                d_model,\n",
    "                n_heads,\n",
    "                d_keys,\n",
    "                d_values,\n",
    "                scale,\n",
    "                attention_dropout,\n",
    "                output_attention,\n",
    "            ),\n",
    "            d_model=d_model,\n",
    "            d_ff=d_ff,\n",
    "            dropout=dropout,\n",
    "            activation=activation,\n",
    "        )\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            enc_layers=[enc_layer for _ in range(num_enc_layers)],\n",
    "            norm_layer=nn.LayerNorm(d_model),\n",
    "        )\n",
    "\n",
    "        # 3. Decoder\n",
    "        if (\n",
    "            self.task_name == \"long_term_forecast\"\n",
    "            or self.task_name == \"short_term_forecast\"\n",
    "        ):\n",
    "            # 3.1 Decoder embedding layer\n",
    "            self.dec_embedding = DataEmbedding(\n",
    "                dec_in, d_model, embed_type, freq, dropout\n",
    "            )\n",
    "\n",
    "            # 3.2 Decoder\n",
    "            dec_layer = DecoderLayer(\n",
    "                self_attention=Attention(\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_keys,\n",
    "                    d_values,\n",
    "                    scale,\n",
    "                    attention_dropout,\n",
    "                    output_attention,\n",
    "                ),\n",
    "                cross_attention=Attention(\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_keys,\n",
    "                    d_values,\n",
    "                    scale,\n",
    "                    attention_dropout,\n",
    "                    output_attention,\n",
    "                ),\n",
    "                d_model=d_model,\n",
    "                d_ff=d_ff,\n",
    "                dropout=dropout,\n",
    "                activation=activation,\n",
    "            )\n",
    "\n",
    "            self.decoder = Decoder(\n",
    "                dec_layers=[dec_layer for _ in range(num_dec_layers)],\n",
    "                norm_layer=nn.LayerNorm(d_model),\n",
    "                projection=nn.Linear(d_model, c_out),\n",
    "            )\n",
    "        elif self.task_name == \"imputation\" or self.task_name == \"anomaly_detection\":\n",
    "            self.projection = nn.Linear(d_model, c_out)\n",
    "        elif self.task_name == \"classification\":\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "            self.projection = nn.Linear(d_model * seq_len, num_class)\n",
    "\n",
    "    def forecast(\n",
    "        self,\n",
    "        past_values: torch.Tensor,\n",
    "        past_time_features: torch.Tensor,\n",
    "        future_values: torch.Tensor,\n",
    "        future_time_features: torch.Tensor,\n",
    "    ):\n",
    "        enc_emb = self.enc_embedding(\n",
    "            x=past_time_features, x_features=past_time_features\n",
    "        )\n",
    "        enc_out, enc_attns = self.encoder(enc_emb)\n",
    "\n",
    "        dec_emb = self.dec_embedding(x=future_values, x_features=future_time_features)\n",
    "        dec_out, dec_attns, cross_attns = self.decoder(dec_emb, enc_out)\n",
    "\n",
    "        return_dict = {\"decoder_hidden_states\": dec_out}\n",
    "        if self.output_attention:\n",
    "            return_dict[\"encoder_attentions\"] = enc_attns\n",
    "            return_dict[\"decoder_attentions\"] = dec_attns\n",
    "            return_dict[\"cross_attentions\"] = cross_attns\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        past_values: torch.Tensor,\n",
    "        past_time_features: torch.Tensor,\n",
    "        future_values: torch.Tensor,\n",
    "        future_time_features: torch.Tensor,\n",
    "    ):\n",
    "        if (\n",
    "            self.task_name == \"long_term_forecast\"\n",
    "            or self.task_name == \"short_term_forecast\"\n",
    "        ):\n",
    "            output = self.forecast(\n",
    "                past_values, past_time_features, future_values, future_time_features\n",
    "            )\n",
    "\n",
    "            return output\n",
    "            # return dec_out[:, -self.pred_len :, :]  # [B, L, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Transformer(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         task_name: str = \"long_term_forecast\",\n",
    "#         pred_len: int = 96,\n",
    "#         enc_in: int = 7,\n",
    "#         dec_in: int = 7,\n",
    "#         c_out: int = 7,\n",
    "#         d_model: int = 512,\n",
    "#         embed_type: str = \"time_features\",\n",
    "#         freq: str = \"h\",\n",
    "#         dropout: float = 0.1,\n",
    "#         n_heads: int = 8,\n",
    "#         d_keys: int = None,\n",
    "#         d_values: int = None,\n",
    "#         d_ff: int = 2048,\n",
    "#         scale: float = None,\n",
    "#         attention_dropout: float = 0.1,\n",
    "#         output_attention: bool = True,\n",
    "#         activation: str = \"gelu\",\n",
    "#         num_enc_layers: int = 2,\n",
    "#         num_dec_layers: int = 1,\n",
    "#     ):\n",
    "#         super(Transformer, self).__init__()\n",
    "\n",
    "#         self.task_name = task_name\n",
    "#         self.pred_len = pred_len\n",
    "#         self.output_attention = output_attention\n",
    "\n",
    "#         self.enc_emb_params = {\n",
    "#             \"c_in\": enc_in,\n",
    "#             \"d_model\": d_model,\n",
    "#             \"embed_type\": embed_type,\n",
    "#             \"freq\": freq,\n",
    "#             \"dropout\": dropout,\n",
    "#         }\n",
    "\n",
    "#         self.dec_emb_params = {\n",
    "#             \"c_in\": dec_in,\n",
    "#             \"d_model\": d_model,\n",
    "#             \"embed_type\": embed_type,\n",
    "#             \"freq\": freq,\n",
    "#             \"dropout\": dropout,\n",
    "#         }\n",
    "\n",
    "#         self.enc_attn_params = {\n",
    "#             \"d_model\": d_model,\n",
    "#             \"n_heads\": n_heads,\n",
    "#             \"d_keys\": d_keys,\n",
    "#             \"d_values\": d_values,\n",
    "#             \"scale\": scale,\n",
    "#             \"attention_dropout\": attention_dropout,\n",
    "#             \"output_attention\": output_attention,\n",
    "#         }\n",
    "\n",
    "#         self.enc_layer_params = {\n",
    "#             \"attention\": Attention(**self.enc_attn_params),\n",
    "#             \"d_model\": d_model,\n",
    "#             \"d_ff\": d_ff,\n",
    "#             \"dropout\": dropout,\n",
    "#             \"activation\": activation,\n",
    "#         }\n",
    "\n",
    "#         self.dec_attn_params = {\n",
    "#             \"d_model\": d_model,\n",
    "#             \"n_heads\": n_heads,\n",
    "#             \"d_keys\": d_keys,\n",
    "#             \"d_values\": d_values,\n",
    "#             \"scale\": scale,\n",
    "#             \"attention_dropout\": attention_dropout,\n",
    "#             \"output_attention\": False,\n",
    "#         }\n",
    "\n",
    "#         self.dec_layer_params = {\n",
    "#             \"self_attention\": Attention(**self.dec_attn_params),\n",
    "#             \"cross_attention\": Attention(**self.dec_attn_params),\n",
    "#             \"d_model\": d_model,\n",
    "#             \"d_ff\": d_ff,\n",
    "#             \"dropout\": dropout,\n",
    "#             \"activation\": activation,\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(**configs._asdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = dm.train_dataloader()\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "# decoder input\n",
    "label_len = 48\n",
    "dec_inp = torch.zeros_like(batch[\"future_values\"][:, -configs.pred_len :, :]).float()\n",
    "dec_inp = torch.cat([batch[\"future_values\"][:, :label_len, :], dec_inp], dim=1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [512, 7, 3], expected input[32, 4, 98] to have 7 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_time_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_inp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfuture_time_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fedtracker/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[62], line 135\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, past_values, past_time_features, future_values, future_time_features)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, past_values: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    128\u001b[0m     past_time_features: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    129\u001b[0m     future_values: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    130\u001b[0m     future_time_features: torch\u001b[38;5;241m.\u001b[39mTensor,):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong_term_forecast\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshort_term_forecast\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m     ):\n\u001b[0;32m--> 135\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "Cell \u001b[0;32mIn[62], line 111\u001b[0m, in \u001b[0;36mTransformer.forecast\u001b[0;34m(self, past_values, past_time_features, future_values, future_time_features)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforecast\u001b[39m(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    106\u001b[0m     past_values: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m     future_time_features: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    110\u001b[0m ):\n\u001b[0;32m--> 111\u001b[0m     enc_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     enc_out, enc_attns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(enc_emb)\n\u001b[1;32m    116\u001b[0m     dec_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec_embedding(x\u001b[38;5;241m=\u001b[39mfuture_values, x_features\u001b[38;5;241m=\u001b[39mfuture_time_features)\n",
      "File \u001b[0;32m~/miniconda3/envs/fedtracker/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/financial/financial_data/teams/mu/excelsiorcjh/TSTF/Transformer/notebook/../src/model/embeddings.py:34\u001b[0m, in \u001b[0;36mDataEmbedding.forward\u001b[0;34m(self, x, x_features)\u001b[0m\n\u001b[1;32m     31\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_embedding(x) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding(x)\n\u001b[1;32m     32\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     x \u001b[39m=\u001b[39m (\n\u001b[0;32m---> 34\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_embedding(x)\n\u001b[1;32m     35\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemporal_embedding(x_features)\n\u001b[1;32m     36\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding(x)\n\u001b[1;32m     37\u001b[0m     )\n\u001b[1;32m     39\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n\u001b[1;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/fedtracker/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/financial/financial_data/teams/mu/excelsiorcjh/TSTF/Transformer/notebook/../src/model/embeddings.py:84\u001b[0m, in \u001b[0;36mTokenEmbedding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 84\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenConv(x\u001b[39m.\u001b[39;49mpermute(\u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/fedtracker/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/fedtracker/lib/python3.9/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/fedtracker/lib/python3.9/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_conv_forward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, weight: Tensor, bias: Optional[Tensor]):\n\u001b[1;32m    305\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m         \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(F\u001b[39m.\u001b[39;49mpad(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_mode),\n\u001b[1;32m    307\u001b[0m                         weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    308\u001b[0m                         _single(\u001b[39m0\u001b[39;49m), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n\u001b[1;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(\u001b[39minput\u001b[39m, weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    310\u001b[0m                     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [512, 7, 3], expected input[32, 4, 98] to have 7 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "output = model(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    future_values=dec_inp,\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
