{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset - ETT Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from gluonts.time_feature import time_features_from_frequency_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path: str, task: str, target: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(data_path)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df = df.set_index(\"date\")\n",
    "\n",
    "    if task == \"S\":\n",
    "        df = df[[target]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trn_val_tst_split(\n",
    "    df: pd.DataFrame, split_idx_dict: dict[str, list[int]], scaler=None\n",
    ") -> dict[str, pd.DataFrame]:\n",
    "    if scaler:\n",
    "        s_idx, e_idx = split_idx_dict[\"train\"]\n",
    "        train_df = df[s_idx:e_idx]\n",
    "        scaler.fit(train_df)\n",
    "        df[df.columns] = scaler.transform(df[df.columns])\n",
    "\n",
    "    data_dict = {}\n",
    "    for stage in split_idx_dict:\n",
    "        s_idx, e_idx = split_idx_dict[stage]\n",
    "        data_dict[stage] = df[s_idx:e_idx]\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 get stamp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stamp_data(df: pd.DataFrame, use_time_enc: bool = True, freq: str = \"h\"):\n",
    "    stamp_df = pd.DataFrame()\n",
    "    stamp_df[\"date\"] = df.index\n",
    "    if use_time_enc:\n",
    "        dates = pd.to_datetime(stamp_df[\"date\"].values)\n",
    "        stamp_data = np.vstack(\n",
    "            [feat(dates) for feat in time_features_from_frequency_str(freq)]\n",
    "        )\n",
    "        stamp_data = stamp_data.transpose(1, 0)\n",
    "    else:\n",
    "        if freq == \"h\":\n",
    "            stamp_df[\"month\"] = stamp_df[\"date\"].apply(lambda row: row.month)\n",
    "            stamp_df[\"day\"] = stamp_df[\"date\"].apply(lambda row: row.day)\n",
    "            stamp_df[\"weekday\"] = stamp_df[\"date\"].apply(lambda row: row.weekday())\n",
    "            stamp_df[\"hour\"] = stamp_df[\"date\"].apply(lambda row: row.hour)\n",
    "            stamp_data = stamp_df.drop([\"date\"], axis=1).values\n",
    "        elif freq == \"t\":\n",
    "            stamp_df[\"month\"] = stamp_df.date.apply(lambda row: row.month, 1)\n",
    "            stamp_df[\"day\"] = stamp_df.date.apply(lambda row: row.day, 1)\n",
    "            stamp_df[\"weekday\"] = stamp_df.date.apply(lambda row: row.weekday(), 1)\n",
    "            stamp_df[\"hour\"] = stamp_df.date.apply(lambda row: row.hour, 1)\n",
    "            stamp_df[\"minute\"] = stamp_df.date.apply(lambda row: row.minute, 1)\n",
    "            stamp_df[\"minute\"] = stamp_df.minute.map(lambda x: x // 15)\n",
    "            stamp_df = stamp_df.drop([\"date\"], 1).values\n",
    "    return stamp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'forecasting task, options:[M, S, MS];\n",
    "#  M:multivariate predict multivariate,\n",
    "#  S:univariate predict univariate,\n",
    "#  MS:multivariate predict univariate'\n",
    "task = \"M\"\n",
    "target = \"OT\"\n",
    "data_path = \"../data/ETT-small/ETTh1.csv\"\n",
    "\n",
    "seq_len = 96\n",
    "label_len = 48\n",
    "pred_len = 96\n",
    "stage = \"train\"\n",
    "use_scaler = True\n",
    "use_time_enc = True\n",
    "freq = \"h\"\n",
    "target = \"OT\"\n",
    "\n",
    "split_idx_dict = {\n",
    "    \"train\": [0, 12 * 30 * 24],\n",
    "    \"val\": [12 * 30 * 24 - seq_len, 12 * 30 * 24 + 4 * 30 * 24],\n",
    "    \"test\": [12 * 30 * 24 + 4 * 30 * 24 - seq_len, 12 * 30 * 24 + 8 * 30 * 24],\n",
    "}\n",
    "\n",
    "scaler = None\n",
    "if use_scaler:\n",
    "    scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(data_path, task=task, target=target)\n",
    "data_dict = trn_val_tst_split(df, split_idx_dict, scaler)\n",
    "train_stamp_data = get_stamp_data(data_dict[\"train\"], use_time_enc, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETTDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        seq_len: int,\n",
    "        label_len: int,\n",
    "        pred_len: int,\n",
    "        freq: str = \"h\",\n",
    "        use_time_enc: bool = True,\n",
    "    ):\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = pred_len\n",
    "        self.freq = freq\n",
    "        self.use_time_enc = use_time_enc\n",
    "\n",
    "        self.input_data = df.values\n",
    "        self.target_data = df.values\n",
    "        self.stamp_data = get_stamp_data(df, use_time_enc, freq)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s_begin = idx\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        past_values = self.input_data[s_begin:s_end]\n",
    "        past_time_features = self.stamp_data[s_begin:s_end]\n",
    "        future_values = self.target_data[r_begin:r_end]\n",
    "        future_time_features = self.stamp_data[r_begin:r_end]\n",
    "\n",
    "        return {\n",
    "            \"past_values\": torch.FloatTensor(past_values),\n",
    "            \"past_time_features\": torch.FloatTensor(past_time_features),\n",
    "            \"future_values\": torch.FloatTensor(future_values),\n",
    "            \"future_time_features\": torch.FloatTensor(future_time_features),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ETTDataset(\n",
    "    data_dict[\"train\"], seq_len, label_len, pred_len, freq, use_time_enc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96, 7])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"past_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 144, 7])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"future_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"past_time_features\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 144, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"future_time_features\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('fedtracker')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "095ffe90df4ca297051b97375d5904c113ac48c02dcabb78607607a5f0a97f85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
